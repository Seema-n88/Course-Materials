{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Models\n",
    "\n",
    "In this exercise, you will construct several graphical models for the MNIST dataset, and perform inference on them to determine the most likely class for each example. You are provided with a modular graphical model implementation (`graphical.py`). It lets you specify the graph (Variables and Factors) in an object oriented fashion and does inference automatically. Because the implementation is generic (it can handle any directed tree), it can be quite slow for large networks.\n",
    "\n",
    "The data is stored in the file `mnist.mat`. The handwritten digits are cropped to 20x20 pixels. The data is accessed through the method `utils.getData()` and returns three matrices: the input `X`, the labels `T`, and some additional data `Z` that will be used in the second part of the exercise.\n",
    "\n",
    "## Example of Execution\n",
    "\n",
    "You are provided with a simple example where the most likely class is inferred based on the number of activated pixels in the top part of the 20x20 image (first 10 rows), and the number of activated pixels (called levels) in the bottom part of the image (last 10 rows). The corresponding graphical model is depicted in the diagram below. The letter V denotes the variables, and the letter F denotes the factors.\n",
    "\n",
    "![scenario1](files/scenario1.png)\n",
    "\n",
    "The sum operator counts the number of white pixels in the corresponding region of the image. Note that this model looses a lot of information (all details within the top and bottom part of the image), and thus, the predictive accuracy is expected to be low (here, ~30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 000  acc: 0.000\n",
      "it: 025  acc: 0.462\n",
      "it: 050  acc: 0.373\n",
      "it: 075  acc: 0.395\n",
      "it: 100  acc: 0.386\n",
      "it: 125  acc: 0.381\n",
      "it: 150  acc: 0.377\n",
      "it: 175  acc: 0.347\n",
      "it: 200  acc: 0.338\n",
      "it: 225  acc: 0.341\n",
      "it: 250  acc: 0.339\n",
      "it: 275  acc: 0.326\n",
      "it: 300  acc: 0.322\n",
      "it: 325  acc: 0.319\n",
      "it: 350  acc: 0.336\n",
      "it: 375  acc: 0.330\n",
      "it: 400  acc: 0.342\n",
      "it: 425  acc: 0.338\n",
      "it: 450  acc: 0.330\n",
      "it: 475  acc: 0.328\n",
      "it: 500  acc: 0.319\n",
      "it: 525  acc: 0.312\n",
      "it: 550  acc: 0.310\n",
      "it: 575  acc: 0.314\n",
      "it: 600  acc: 0.314\n",
      "it: 625  acc: 0.315\n",
      "it: 650  acc: 0.316\n",
      "it: 675  acc: 0.320\n",
      "it: 700  acc: 0.324\n",
      "it: 725  acc: 0.321\n",
      "it: 750  acc: 0.322\n",
      "it: 775  acc: 0.322\n",
      "it: 800  acc: 0.323\n",
      "it: 825  acc: 0.326\n",
      "it: 850  acc: 0.321\n",
      "it: 875  acc: 0.321\n",
      "it: 900  acc: 0.324\n",
      "it: 925  acc: 0.325\n",
      "it: 950  acc: 0.328\n",
      "it: 975  acc: 0.326\n",
      "Accuracy: 0.325\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import numpy\n",
    "from graphical import *\n",
    "\n",
    "X,T,_ = utils.getData()\n",
    "    \n",
    "nbclasses = 10\n",
    "nblevels  = 201\n",
    "\n",
    "# =========================================\n",
    "# BUILD THE MODEL\n",
    "# =========================================\n",
    "\n",
    "# -----------------------------------------\n",
    "# Compute the evidence for VX1 and VX2\n",
    "# -----------------------------------------\n",
    "Xtop = X[:,:10,:].sum(axis=2).sum(axis=1)\n",
    "Xbot = X[:,10:,:].sum(axis=2).sum(axis=1)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Define the variable nodes\n",
    "# -----------------------------------------\n",
    "VT  = VariableNode(\"VT\",nbclasses)\n",
    "VX1 = VariableNode(\"VX1\",nblevels)\n",
    "VX2 = VariableNode(\"VX2\",nblevels)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Compute class factors\n",
    "# -----------------------------------------\n",
    "nbexamples = numpy.zeros([nbclasses])\n",
    "for cl in range(nbclasses):\n",
    "    nbexamples[cl] = (T==cl).sum()\n",
    "    \n",
    "PT = (nbexamples+1) / (nbexamples+1).sum() # adding 1 avoids log(0)\n",
    "FT = FactorNode(\"FT\",numpy.log(PT),[VT])\n",
    "\n",
    "# -----------------------------------------\n",
    "# Compute class-level factors (top)\n",
    "# -----------------------------------------\n",
    "nbexamples = numpy.zeros([nbclasses,nblevels])\n",
    "for cl in range(nbclasses):\n",
    "    x = Xtop[T==cl]\n",
    "    for lv in range(nblevels):\n",
    "        nbexamples[cl,lv] = (x==lv).sum()\n",
    "\n",
    "PXT1 = (nbexamples+1) / (nbexamples+1).sum(axis=1)[:,numpy.newaxis] # adding 1 avoids log(0)\n",
    "FXT1 = FactorNode(\"FXT\",numpy.log(PXT1),[VT,VX1])\n",
    "\n",
    "# -----------------------------------------\n",
    "# Compute class-level factors (bottom)\n",
    "# -----------------------------------------\n",
    "nbexamples = numpy.zeros([nbclasses,nblevels])\n",
    "for cl in range(nbclasses):\n",
    "    x = Xbot[T==cl]\n",
    "    for lv in range(nblevels):\n",
    "        nbexamples[cl,lv] = (x==lv).sum()\n",
    "        \n",
    "PXT2 = (nbexamples+1) / (nbexamples+1).sum(axis=1)[:,numpy.newaxis] # adding 1 avoids log(0)\n",
    "FXT2 = FactorNode(\"FXT\",numpy.log(PXT2),[VT,VX2])\n",
    "\n",
    "# =========================================\n",
    "# INFER CLASSES FOR TEST DATA\n",
    "# =========================================\n",
    "def predict(x):\n",
    "    VX1.evidence = x[:10,:].sum()\n",
    "    VX2.evidence = x[10:,:].sum()\n",
    "    VT.initiateMessagePassing(None)\n",
    "    return numpy.argmax(VT.computeMarginal())\n",
    "\n",
    "print('Accuracy: %.3f'%utils.getAccuracy(predict,debug=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Model (25 P)\n",
    "\n",
    "We would like to modify the model above in the following way: We define 400 input nodes (as many nodes as pixels of the 20x20 image) with two possible states (black or white). Each input node is connected to the class node. Given a particular class is observed, the input nodes are assumed to be independent. A diagram of the proposed model is given below:\n",
    "\n",
    "\n",
    "![scenario2](files/scenario2.png)\n",
    "\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "* **Implement the graphical model shown above. Set the factors to their most likely value given the data (X,T). Use the same variable names as in the diagram above. (20 P)**\n",
    "\n",
    "* **Print the classification accuracy of the graphical model you have implemented. (5 P)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 000  acc: 1.000\n",
      "it: 025  acc: 0.885\n",
      "it: 050  acc: 0.843\n",
      "it: 075  acc: 0.855\n",
      "it: 100  acc: 0.851\n",
      "it: 125  acc: 0.841\n",
      "it: 150  acc: 0.841\n",
      "it: 175  acc: 0.847\n",
      "it: 200  acc: 0.841\n",
      "it: 225  acc: 0.850\n",
      "it: 250  acc: 0.853\n",
      "it: 275  acc: 0.855\n",
      "it: 300  acc: 0.844\n",
      "it: 325  acc: 0.837\n",
      "it: 350  acc: 0.840\n",
      "it: 375  acc: 0.840\n",
      "it: 400  acc: 0.838\n",
      "it: 425  acc: 0.833\n",
      "it: 450  acc: 0.834\n",
      "it: 475  acc: 0.836\n",
      "it: 500  acc: 0.834\n",
      "it: 525  acc: 0.831\n",
      "it: 550  acc: 0.828\n",
      "it: 575  acc: 0.830\n",
      "it: 600  acc: 0.829\n",
      "it: 625  acc: 0.824\n",
      "it: 650  acc: 0.829\n",
      "it: 675  acc: 0.828\n",
      "it: 700  acc: 0.827\n",
      "it: 725  acc: 0.824\n",
      "it: 750  acc: 0.823\n",
      "it: 775  acc: 0.822\n",
      "it: 800  acc: 0.820\n",
      "it: 825  acc: 0.823\n",
      "it: 850  acc: 0.826\n",
      "it: 875  acc: 0.826\n",
      "it: 900  acc: 0.828\n",
      "it: 925  acc: 0.828\n",
      "it: 950  acc: 0.829\n",
      "it: 975  acc: 0.826\n",
      "Accuracy: 0.828\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import numpy\n",
    "from graphical import *\n",
    "\n",
    "X,T,_ = utils.getData()\n",
    "\n",
    "nbclasses = 10 # 0 to 9\n",
    "nblevels = 2 # number of states each variable can have (black/white: 2)\n",
    "nbpixels = 400\n",
    "\n",
    "# =========================================\n",
    "# BUILD THE MODEL\n",
    "# =========================================\n",
    "\n",
    "# -----------------------------------------\n",
    "# Define the variable nodes\n",
    "# -----------------------------------------\n",
    "VT = VariableNode(\"VT\",nbclasses)\n",
    "VX = []\n",
    "for i in range(nbpixels):\n",
    "    VX.append(VariableNode(\"VX\"+str(i),nblevels))\n",
    "\n",
    "# -----------------------------------------\n",
    "# Compute class factors\n",
    "# Probability of being in each class\n",
    "# -----------------------------------------\n",
    "nbexamples = numpy.zeros([nbclasses])\n",
    "for cl in range(nbclasses):\n",
    "    # Contains sum of elements of that class\n",
    "    # e.g.: nbexamples[1] = 17 means that there is 17 times a \"1\" in the label set\n",
    "    nbexamples[cl] = (T==cl).sum()\n",
    "\n",
    "# Calculate probablity that this class occurs = probablity for every label\n",
    "# e.g.: We have 100 labels and 17 are \"1\", than we have P(\"1\")=17/100=0.17\n",
    "PT = (nbexamples+1) / (nbexamples+1).sum() # adding 1 avoids log(0)\n",
    "FT = FactorNode(\"FT\",numpy.log(PT),[VT])\n",
    "\n",
    "# -----------------------------------------\n",
    "# Compute class-level factors\n",
    "# Probability that for class cl for each pixel the level is lv\n",
    "# -----------------------------------------\n",
    "nbexamples = numpy.zeros([nbclasses,nbpixels,nblevels])\n",
    "for cl in range(nbclasses):\n",
    "    # Get all data (pixels and levels), where label is cl\n",
    "    x = X[T==cl,:,:]\n",
    "    for lv in range(nblevels):\n",
    "        # Get all data (pixels), where level is lv\n",
    "        # and sum over pixels\n",
    "        nbexamples[cl,:,lv] = (x==lv).sum(axis=0).reshape((1,nbpixels))\n",
    "\n",
    "# Calculate probability for the labels using pixel sums for every label\n",
    "PXT = (nbexamples+1) / (nbexamples+1).sum(axis=1)[:,numpy.newaxis,:] # adding 1 avoids log(0)\n",
    "FXT = []\n",
    "for px in range(nbpixels):\n",
    "    FXT.append(FactorNode(\"FXT\"+str(px),numpy.log(PXT[:,px,:]),[VT,VX[px]]))\n",
    "\n",
    "# =========================================\n",
    "# INFER CLASSES FOR TEST DATA\n",
    "# =========================================\n",
    "\n",
    "def predict(x):\n",
    "    for i in range(nbpixels):\n",
    "        cols = x.shape[1]\n",
    "        VX[i].evidence = x[i/cols,i%cols]\n",
    "    VT.initiateMessagePassing(None)\n",
    "    return numpy.argmax(VT.computeMarginal())\n",
    "\n",
    "print('Accuracy: %.3f'%utils.getAccuracy(predict,debug=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Model (25 P)\n",
    "\n",
    "We now would like to construct a more complex architecture consisting of two layers. There are 400 input nodes that are separated into 16 groups representing local regions of the image of size 5x5. As in the previous model, each input node has 2 possible states (black or white). Each input node is only connected to its associated group node that has 12 possible states (called subclasses). The state of these group nodes is available for the training data and is returned by the method `utils.getData()`, and can therefore be used to set the factors of the hierarchical model. All group nodes are connected to the top-level class node. In this hierarchical model, the group nodes are independent given the class is known, and the pixel values within a patch are independent given that the state of the associated group node is known. However, the pixels within the same group are no longer independent given the class only. These correlations caused by the unknown state of the group node confer added representational power to the model. A diagram of the model is given below:\n",
    "\n",
    "![scenario3](files/scenario3.png)\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "* **Implement the graphical model shown above. Set the factors to their most likely value given the data (X,T,Z). Use the same variable names as in the diagram above. (20 P)**\n",
    "\n",
    "* **Print the classification accuracy of the graphical model you have implemented. (5 P)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# No solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
